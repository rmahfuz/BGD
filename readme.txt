Written by Rehana on 12/05/2016 @ 3:57 am
=======================================================================================================================================================================================================================
Scenario: Each agent has its own data of the form y = beta*x + W, where beta is an underlying truth to be learnt, and W is the noise.

Each co-operative agent updates its local estimate according to the formula:
x[t+1] = prev_b + step_size*gradient evaluated at prev_b
prev_b is the average of all the agent's local estimates at time 't'
step size is taken as (1/t)
gradient is different for each agent, as the data is different. The general formula is 
gradient evaluated at 'b' = sum from i = 1 to cardinality (y_i - b*x_i), where (x_i,y_i) is the ith data point.

The selfish agent's update rule is:
x[t+1] = x[t] + step size*gradient evaluated at x[t]

Initialization of local estimates: local estimate of agent i at t = 0 = sum(y)/sum(x)

Observation: The selfish agent's gradient (y - beta*x) is very small (about 10^(-16) orders of magnitude lesser than other agents' gradients). This makes sense because:
At t = 1, gradient of the selfish agent = y - {sum(y)/sum(x)}*x. sum(x) is very close to x, and y is very close to sum(y), which is why this gradient is very small.

As a result of the selfish agent's gradient being so small, its local estimate x[t+1] = x[t] - step size*gradient(x[t]) changes very less, since a very small value is being subtracted from it.

________________________________________________________________________________________________________________________________________________________________________________________________________________________

In the data below, the 6th agent is the selfish agent (if you consider the starting agent to be 1st). Each row is the local estimate at a particular time 't', where t is from 0 to 19.

0
[ 0.92366412  0.53240741  0.78443114  0.527897    1.01834862  0.84401709
  0.97188755  0.96012759  1.11680328  0.86354379]


1
[ 0.81797264  0.99337587  0.87765322  1.0064225   0.80067303  0.84401709
  0.79576051  0.78796686  0.72621739  0.84978032]


2
[ 0.83067974  0.91858048  0.86093126  0.9250302   0.82245632  0.84401709
  0.81962995  0.81545391  0.78488003  0.846655  ]


3
[ 0.83341128  0.89210845  0.85377863  0.89637254  0.82813602  0.84401709
  0.82607208  0.82315249  0.80291597  0.84409614]


4
[ 0.83402327  0.87810193  0.84941398  0.88127938  0.83018627  0.84401709
  0.82853463  0.82626672  0.81117361  0.84205692]


5
[ 0.83399994  0.86929784  0.84638474  0.87182688  0.83100523  0.84401709
  0.82961891  0.82775555  0.8157339   0.84043941]


6
[ 0.83378931  0.86322719  0.84415739  0.86532623  0.83134288  0.84401709
  0.83014494  0.82855995  0.8185766   0.83916377]


7
[ 0.83355499  0.85880293  0.84247388  0.8605964   0.83149119  0.84401709
  0.83043562  0.82905536  0.82052158  0.83816722]


8
[ 0.83336034  0.85546285  0.84118619  0.85702823  0.83157714  0.84401709
  0.83063388  0.82941133  0.82196024  0.83739983]


9
[ 0.83322802  0.85288193  0.84019927  0.8542707   0.83165845  0.84401709
  0.83080654  0.82970968  0.82309742  0.83682127]


10
[ 0.83316289  0.85085634  0.83944718  0.85210441  0.83176081  0.84401709
  0.83098496  0.82999089  0.82404729  0.83639859]


11
[ 0.83316188  0.84925011  0.83888164  0.85038351  0.83189428  0.84401709
  0.83118286  0.83027456  0.82487625  0.83610459]


12
[ 0.83321846  0.84796811  0.83846592  0.84900628  0.832061    0.84401709
  0.83140496  0.8305694   0.82562412  0.8359167 ]


13
[ 0.83332493  0.84694124  0.83817133  0.84789909  0.83225919  0.84401709
  0.83165128  0.83087824  0.82631526  0.83581606]


14
[ 0.83347345  0.84611782  0.83797501  0.84700701  0.83248522  0.84401709
  0.83191953  0.8312008   0.82696473  0.83578688]


15
[ 0.83365662  0.84545823  0.83785849  0.84628807  0.8327347   0.84401709
  0.83220635  0.83153526  0.82758189  0.8358159 ]


16
[ 0.83386769  0.84493157  0.83780669  0.84570959  0.83300313  0.84401709
  0.83250802  0.83187904  0.82817258  0.83589196]


17
[ 0.83410062  0.84451335  0.83780721  0.84524573  0.83328619  0.84401709
  0.83282084  0.83222934  0.82874039  0.8360057 ]


18
[ 0.83435017  0.84418391  0.8378498   0.84487579  0.83357991  0.84401709
  0.83314134  0.83258341  0.82928752  0.83614923]


19
[ 0.83461176  0.84392733  0.83792595  0.84458302  0.83388074  0.84401709
  0.83346639  0.83293867  0.82981534  0.83631592]

________________________________________________________________________________________________________________________________________________________________________________________________________________________


The following is local estimates when there is no selfish agent:
0
[ 0.92366412  0.53240741  0.78443114  0.527897    1.01834862  0.84401709
  0.97188755  0.96012759  1.11680328  0.86354379]


1
[ 0.81797264  0.99337587  0.87765322  1.0064225   0.80067303  0.85913113
  0.79576051  0.78796686  0.72621739  0.84978032]


2
[ 0.83258713  0.92041834  0.86269507  0.92689376  0.82421484  0.85324526
  0.82151769  0.81743914  0.78676021  0.84853746]


3
[ 0.83646482  0.89508227  0.85666753  0.89937582  0.83101886  0.85027544
  0.82910309  0.82629528  0.80593832  0.84712108]


4
[ 0.83778744  0.88178955  0.85302006  0.88499529  0.83378653  0.84816916
  0.83227716  0.83011659  0.81490783  0.84579363]


5
[ 0.83815282  0.87338156  0.85039478  0.87593616  0.83501001  0.84647466
  0.83375225  0.83198587  0.81985972  0.84456748]


6
[ 0.8380773   0.86745471  0.8483205   0.8695761   0.83550139  0.84502442
  0.83441584  0.83291563  0.82284092  0.84343007]


7
[ 0.83777397  0.86297033  0.84658632  0.86478285  0.8355997   0.84373821
  0.83464002  0.83333209  0.82472037  0.84236769]


8
[ 0.83734481  0.85940432  0.84508184  0.86098559  0.83546952  0.84257125
  0.83460619  0.83344394  0.82592788  0.84136887]


9
[ 0.83684365  0.85646265  0.84374278  0.85786432  0.8351993   0.84149579
  0.83441231  0.83336442  0.82669939  0.84042438]


10
[ 0.83630101  0.85396702  0.84252864  0.85522523  0.83484018  0.84049336
  0.83411531  0.83315971  0.82717466  0.83952686]


11
[ 0.83573503  0.85180272  0.84141237  0.85294371  0.83442345  0.83955094
  0.83375021  0.83287072  0.82744136  0.83867038]


12
[ 0.83515698  0.84989239  0.84037503  0.85093582  0.83396903  0.83865897
  0.83333945  0.83252386  0.82755707  0.83785011]


13
[ 0.83457399  0.84818181  0.83940284  0.8491428   0.83349006  0.83781019
  0.83289794  0.83213681  0.827561    0.83706208]


14
[ 0.83399069  0.84663178  0.83848548  0.84752219  0.83299544  0.83699893
  0.83243585  0.83172171  0.82748068  0.83630295]


15
[ 0.83341012  0.84521319  0.837615    0.84604249  0.83249132  0.83622068
  0.83196026  0.83128712  0.82733596  0.83556992]


16
[ 0.83283426  0.8439039   0.83678515  0.84467979  0.83198202  0.83547176
  0.83147622  0.83083917  0.8271414   0.8348606 ]


17
[ 0.83226441  0.84268677  0.83599091  0.84341559  0.83147061  0.83474912
  0.83098735  0.83038233  0.82690794  0.83417294]


18
[ 0.83170139  0.84154829  0.8352282   0.8422353   0.8309593   0.83405023
  0.83049629  0.8299199   0.8266439   0.83350517]


19
[ 0.83114572  0.84047762  0.83449364  0.84112727  0.83044967  0.83337292
  0.83000496  0.82945434  0.82635568  0.83285573]
